<!DOCTYPE HTML>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <meta name="Keywords" content="blog"/>
    <meta name="Description" content="blog"/>
    <title>Simple</title>
    <link rel="shortcut icon" href="/static/favicon.png"/>
    <link rel="stylesheet" type="text/css" href="/main.css" />
</head>
<body>
<div class="main">
    <div class="header">
    	<ul id="pages">
            <li><a href="/">home</a></li>
            <li><a href="/#/tags">tags</a></li>
            <li><a href="/#/archive">archive</a></li>
    	</ul>
    </div>
	<div class="wrap-header">
	<h1>
    <a href="/" id="title"></a>
	</h1>
	</div>
<div id="md" style="display: none;">
<!-- markdown -->
**一、Spark编程中的重要概念：**（具体实例  P10）

**1.弹性分布式数据集RDD（Resilient Distributed DataSets）**

**2.创建操作（creation operation）**  
RDD的*初始创建都是由SparkContext来负责*的，将内存中的集合或者外部文件系统作为输入源。

**3.转换操作（transformation operation）**   
将一个RDD*通过一定的操作*变换成另一个RDD。

**4.控制操作  （control operation）**  
对RDD进行持久化，可以*让RDD保存在磁盘或者内存中*，以便后续重复使用。  

cache():RDD[T]    
persist():RDD[T]    
persist(level:StorageLevel):RDD[T]  

checkpoint()      &emsp;      checkpoint会割断此RDD之前的依赖关系，而persist接口依然保留着RDD的依赖关系


**5.行动操作（action operation）**  
由于Spark是惰性计算的，所以对于任何RDD进行行动操作，都会触发Spark作业的运行，从而产生最终的结果。   
Spark中的行动操作基本分为两类：一类的操作结果变成Scala集合或者标量，另一类就将RDD保存到外部文件或者数据库系统中。

**(1)集合标量行动操作**［行动操作将标量活着集合返回给Spark的客户端程序］  
first  
count  
reduce(f:(T,T)=>T)  对RDD中的元素进行二元计算，返回计算结果  

collect()/toArray()   以集合形式返回RDD的元素
take(num:Int)  
top(num:Int)    
takeOrdered(num:Int) &emsp; 以与top相反的排序规则返回

**(2)存储行动操作** ［行动操作将RDD直接保存到外部文件系统活着数据库中］

**对于一个Spark数据处理程序而言，一般情况下，经过输入操作（创建操作）、转换操作、控制操作、输出操作（行动操作）来完成一个作业。**  
当然一个Spark应用程序中，可以有多个行动操作，也就是有多个作业存在。


**二、Spark RDD**  
一个RDD代表一个被分区的只读数据集。  
一个RDD的生成只有两种途径：  
（1）来自于内存集合和外部存储系统  
（2）通过转换操作来自于其他RDD（如map、filter、join等）  
**RDD是粗粒度的操作数据集**    （每一个转换操作都会生成一个新的RDD）（一个操作会被应用在RDD的所有数据上）    
**所以只要通过记录下这些作用在RDD之上的转化操作，来构建RDD的继承关系（ lineage），就可以有效地进行容错处理，而不需要将实际的RDD数据进行记录拷贝**  

**1.RDD分区（partitions）**  
可以指定多少分区，也可以不指定（采用系统默认的分区数----程序所分配到的资源的CPU核的个数）  
**2.RDD优先位置（preferredLocations）**   
preferredLocations返回每一个数据块所在的机器名或者 IP地址（如果每一块数据是多份存储的，那么就会返回多个机器地址）  
**3.RDD依赖关系（dependencies）**    
*窄依赖*：每一个父RDD的分区最多只被子RDD的一个分区所使用。  
*宽依赖*：多个子RDD的分区会依赖于同一个父RDD的分区。   
org.apache.spark.*OneToOneDependency*（窄依赖）
org.apache.spark.*ShuffleDependency* （宽依赖）  
**4.RDD区分计算（compute）**   
对于Spark中每个RDD的计算都是以partition(分区)为单位的，而且RDD中的compute函数都是在对迭代器进行复合，不需要保存每次计算的结果。    
**5.RDD分区函数（partitioner）**    
目前在Spark中实现了两种类型的分区函数：
HashPatitioner（哈希分区）和RangePatitioner（区域分区）

partitioner这个属性，只存在于（K,V）类型的RDD中，对于非（K,V）类型的partitioner的值就是None。













<!-- markdown end -->
</div>
<div class="entry" id="main">
<!-- content -->
<p><strong>一、Spark编程中的重要概念：</strong>（具体实例  P10）</p>

<p><strong>1.弹性分布式数据集RDD（Resilient Distributed DataSets）</strong></p>

<p><strong>2.创建操作（creation operation）</strong> <br>
RDD的<em>初始创建都是由SparkContext来负责</em>的，将内存中的集合或者外部文件系统作为输入源。</p>

<p><strong>3.转换操作（transformation operation）</strong> <br>
将一个RDD<em>通过一定的操作</em>变换成另一个RDD。</p>

<p><strong>4.控制操作  （control operation）</strong> <br>
对RDD进行持久化，可以<em>让RDD保存在磁盘或者内存中</em>，以便后续重复使用。  </p>

<p>cache():RDD[T] <br>
persist():RDD[T] <br>
persist(level:StorageLevel):RDD[T]  </p>

<p>checkpoint()             checkpoint会割断此RDD之前的依赖关系，而persist接口依然保留着RDD的依赖关系</p>

<p><strong>5.行动操作（action operation）</strong> <br>
由于Spark是惰性计算的，所以对于任何RDD进行行动操作，都会触发Spark作业的运行，从而产生最终的结果。 <br>
Spark中的行动操作基本分为两类：一类的操作结果变成Scala集合或者标量，另一类就将RDD保存到外部文件或者数据库系统中。</p>

<p><strong>(1)集合标量行动操作</strong>［行动操作将标量活着集合返回给Spark的客户端程序］ <br>
first <br>
count <br>
reduce(f:(T,T)=&gt;T)  对RDD中的元素进行二元计算，返回计算结果  </p>

<p>collect()/toArray()   以集合形式返回RDD的元素
take(num:Int) <br>
top(num:Int) <br>
takeOrdered(num:Int)   以与top相反的排序规则返回</p>

<p><strong>(2)存储行动操作</strong> ［行动操作将RDD直接保存到外部文件系统活着数据库中］</p>

<p><strong>对于一个Spark数据处理程序而言，一般情况下，经过输入操作（创建操作）、转换操作、控制操作、输出操作（行动操作）来完成一个作业。</strong> <br>
当然一个Spark应用程序中，可以有多个行动操作，也就是有多个作业存在。</p>

<p><strong>二、Spark RDD</strong> <br>
一个RDD代表一个被分区的只读数据集。 <br>
一个RDD的生成只有两种途径： <br>
（1）来自于内存集合和外部存储系统 <br>
（2）通过转换操作来自于其他RDD（如map、filter、join等） <br>
<strong>RDD是粗粒度的操作数据集</strong>    （每一个转换操作都会生成一个新的RDD）（一个操作会被应用在RDD的所有数据上） <br>
<strong>所以只要通过记录下这些作用在RDD之上的转化操作，来构建RDD的继承关系（ lineage），就可以有效地进行容错处理，而不需要将实际的RDD数据进行记录拷贝</strong>  </p>

<p><strong>1.RDD分区（partitions）</strong> <br>
可以指定多少分区，也可以不指定（采用系统默认的分区数----程序所分配到的资源的CPU核的个数） <br>
<strong>2.RDD优先位置（preferredLocations）</strong> <br>
preferredLocations返回每一个数据块所在的机器名或者 IP地址（如果每一块数据是多份存储的，那么就会返回多个机器地址） <br>
<strong>3.RDD依赖关系（dependencies）</strong> <br>
<em>窄依赖</em>：每一个父RDD的分区最多只被子RDD的一个分区所使用。 <br>
<em>宽依赖</em>：多个子RDD的分区会依赖于同一个父RDD的分区。 <br>
org.apache.spark.<em>OneToOneDependency</em>（窄依赖）
org.apache.spark.<em>ShuffleDependency</em> （宽依赖） <br>
<strong>4.RDD区分计算（compute）</strong> <br>
对于Spark中每个RDD的计算都是以partition(分区)为单位的，而且RDD中的compute函数都是在对迭代器进行复合，不需要保存每次计算的结果。 <br>
<strong>5.RDD分区函数（partitioner）</strong> <br>
目前在Spark中实现了两种类型的分区函数：
HashPatitioner（哈希分区）和RangePatitioner（区域分区）</p>

<p>partitioner这个属性，只存在于（K,V）类型的RDD中，对于非（K,V）类型的partitioner的值就是None。</p>
<!-- content end -->
</div>
<br>
<br>
    <div id="disqus_thread"></div>
	<div class="footer">
		<p>© Copyright 2014 by isnowfy, Designed by isnowfy</p>
	</div>
</div>
<script src="main.js"></script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ["\\(", "\\)"]], processEscapes: true}});
</script>
<script id="content" type="text/mustache">
    <h1>{{title}}</h1>
    <div class="tag">
    {{date}}
    {{#tags}}
    <a href="/#/tag/{{name}}">#{{name}}</a>
    {{/tags}}
    </div>
</script>
<script id="pagesTemplate" type="text/mustache">
    {{#pages}}
    <li>
        <a href="{{path}}">{{title}}</a>
    </li>
    {{/pages}}
</script>
<script>
$(document).ready(function() {
    $.ajax({
        url: "main.json",
        type: "GET",
        dataType: "json",
        success: function(data) {
            $("#title").html(data.name);
            var pagesTemplate = Hogan.compile($("#pagesTemplate").html());
            var pagesHtml = pagesTemplate.render({"pages": data.pages});
            $("#pages").append(pagesHtml);
            //path
            var path = "rdd_interface.html";
            //path end
            var now = 0;
            for (var i = 0; i < data.posts.length; ++i)
                if (path == data.posts[i].path)
                    now = i;
            var post = data.posts[now];
            var tmp = post.tags.split(" ");
            var tags = [];
            for (var i = 0; i < tmp.length; ++i)
                if (tmp[i].length > 0)
                    tags.push({"name": tmp[i]});
            var contentTemplate = Hogan.compile($("#content").html());
            var contentHtml = contentTemplate.render({"title": post.title, "tags": tags, "date": post.date});
            $("#main").prepend(contentHtml);
            if (data.disqus_shortname.length > 0) {
                var disqus_shortname = data.disqus_shortname;
                (function() {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            }
        }
    });
});
</script>
</body>
</html>
