<!DOCTYPE HTML>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <meta name="Keywords" content="blog"/>
    <meta name="Description" content="blog"/>
    <title>Simple</title>
    <link rel="shortcut icon" href="/static/favicon.png"/>
    <link rel="stylesheet" type="text/css" href="/main.css" />
</head>
<body>
<div class="main">
    <div class="header">
    	<ul id="pages">
            <li><a href="/">home</a></li>
            <li><a href="/#/tags">tags</a></li>
            <li><a href="/#/archive">archive</a></li>
    	</ul>
    </div>
	<div class="wrap-header">
	<h1>
    <a href="/" id="title"></a>
	</h1>
	</div>
<div id="md" style="display: none;">
<!-- markdown -->
大数据处理框架

***集群*环境  对于编程带来的挑战**：

1.并行化：
   以并行化的方式重写应用程序——>利用更大范围节点的计算能力

2.单点失败的处理：
   节点宕机，以及个别节点计算缓慢

3.动态地进行计算资源的分配
   
**历史**：  
1.Google的MapReduce：展示了一个简单通用和自动容错的批处理计算模型。  
但对其他类型的计算（如交互式和流式计算）不合适。  

2.于是出现，专有的数据处理模型（如Storm,Impala,GraphLab），但也有不足（重复工作，组合问题，适用范围的局限性，资源分配，管理问题）。

——>3.统一大数据处理框架Spark  

某种程度上是对MapReduce模型的一种扩展：在MapReduce上实现其不擅长的计算工作（如迭代式，交互式和流式）。
困难点在于 MapReduce缺乏一种特性（在并行计算的各个阶段进行有效的数据共享——>RDD的本质）。  

利用这种有效地数据共享和类似MapReduce的操作接口，  
上述的各种专有类型计算都能够有效的表达，而且能够获得与专有系统同等的性能。

**值得一提的是**，  
从前对于集群处理容错的方式（如MapReduce和Dryad）是将计算构建成一个有向无环图的任务集，这只能允许它们有效地重新计算部分DAG。在单独的计算之间（在迭代的计算步骤之间），除了复制文件，这些模型没有提供其他的存储抽象，这就显著地增加了在网络之间复制文件的代价。    
*RDD能够使用当前大部分的数据并行算法和编程模型*。

**RDD表达能力**  
使用RDD可以实现很多现有的集群编程模型以及一些以前的模型不支持的新应用。  
在这些模型中，RDD能够取得和专有系统同样的性能，还能提供包括容错处理、滞后节点（straggler node）处理等*这些专有系统缺乏的特性*。

四类模型：  
1.迭代算法  ——专有系统 ，图处理、机器学习  
2.关系型查询  ——SQL查询  
3.MapReduce批处理  ——` RDD提供的接口是MapReduce的超集，RDD可以有效地运行MapReduce实现的应用程序`。  
4.流式处理  ——重要多理解（P4）
 `RDD实现了一种新的模型（离散数据流，D-Stream）`


**Spark子系统**  
大数据处理场景：   1.batch data processing  
&emsp;&emsp;&emsp;&emsp;&emsp; &emsp;&emsp;&emsp;   2.interactive query  
&emsp;&emsp;&emsp;&emsp;&emsp; &emsp;&emsp;&emsp;   3.streaming data processing  
————>  
`Spark Core`：*基于RDD提供了丰富的操作接口，利用**DAG**进行统一的任务规划*。使得Spark能够更加灵活地处理类似MapReduce的批处理作业。  
`在Spark Core之上，有Shark/Spark SQL、Spark Streaming、GraphX、MLlib`。

 `Spark生态系统的目标：`
将*批处理、交互式处理、流式处理*融合到同一个**软件栈**中。

`对于最终的用户或者开发者而言，Spark生态系统有如下特性：`  
1.**Spark生态系统兼容Hadoop生态系统**  ——   
完美兼容Hadoop生态中的HDFS和YARN等其他组件，使得现有的Hadoop用户能够非常容易地迁移到Spark系统中（虽然Spark通用引擎在一定程度上是用来取代MapReduce系统的）

2.**Spark生态系统学习成本很低**  
`开发者对Spark Core的原理有比较深入的理解，对架构在Spark Core之上的其他组件的运用将会非常容易。`  
3.**Spark性能表现优异**  
 由于Spark利用*DAG*进行调度执行规划，所以在多任务计算以及迭代计算中能够大量减少磁盘I/O的时间。  
对于每一项任务*启动一个线程*，而不是启动一个进程，大大缩短了任务启动时间。  
4.**Spark有强大的社区支持**  
Spark创业团队成立Databricks公司，全力支持Spark生态的发展。  
5.**Spark支持多种语言编程接口**  
*Spark生态本身是使用Scala语言编写的*，
考虑到流行性，Spark从一开始就支持Java和Python接口，方便开发者自由选择。


<!-- markdown end -->
</div>
<div class="entry" id="main">
<!-- content -->
<p>大数据处理框架</p>

<p><strong><em>集群</em>环境  对于编程带来的挑战</strong>：</p>

<p>1.并行化：
   以并行化的方式重写应用程序——&gt;利用更大范围节点的计算能力</p>

<p>2.单点失败的处理：
   节点宕机，以及个别节点计算缓慢</p>

<p>3.动态地进行计算资源的分配</p>

<p><strong>历史</strong>： <br>
1.Google的MapReduce：展示了一个简单通用和自动容错的批处理计算模型。 <br>
但对其他类型的计算（如交互式和流式计算）不合适。  </p>

<p>2.于是出现，专有的数据处理模型（如Storm,Impala,GraphLab），但也有不足（重复工作，组合问题，适用范围的局限性，资源分配，管理问题）。</p>

<p>——&gt;3.统一大数据处理框架Spark  </p>

<p>某种程度上是对MapReduce模型的一种扩展：在MapReduce上实现其不擅长的计算工作（如迭代式，交互式和流式）。
困难点在于 MapReduce缺乏一种特性（在并行计算的各个阶段进行有效的数据共享——&gt;RDD的本质）。  </p>

<p>利用这种有效地数据共享和类似MapReduce的操作接口， <br>
上述的各种专有类型计算都能够有效的表达，而且能够获得与专有系统同等的性能。</p>

<p><strong>值得一提的是</strong>， <br>
从前对于集群处理容错的方式（如MapReduce和Dryad）是将计算构建成一个有向无环图的任务集，这只能允许它们有效地重新计算部分DAG。在单独的计算之间（在迭代的计算步骤之间），除了复制文件，这些模型没有提供其他的存储抽象，这就显著地增加了在网络之间复制文件的代价。 <br>
<em>RDD能够使用当前大部分的数据并行算法和编程模型</em>。</p>

<p><strong>RDD表达能力</strong> <br>
使用RDD可以实现很多现有的集群编程模型以及一些以前的模型不支持的新应用。 <br>
在这些模型中，RDD能够取得和专有系统同样的性能，还能提供包括容错处理、滞后节点（straggler node）处理等<em>这些专有系统缺乏的特性</em>。</p>

<p>四类模型： <br>
1.迭代算法  ——专有系统 ，图处理、机器学习 <br>
2.关系型查询  ——SQL查询 <br>
3.MapReduce批处理  ——<code>RDD提供的接口是MapReduce的超集，RDD可以有效地运行MapReduce实现的应用程序</code>。 <br>
4.流式处理  ——重要多理解（P4）
 <code>RDD实现了一种新的模型（离散数据流，D-Stream）</code></p>

<p><strong>Spark子系统</strong> <br>
大数据处理场景：   1.batch data processing <br>
            2.interactive query <br>
            3.streaming data processing <br>
————&gt; <br>
<code>Spark Core</code>：<em>基于RDD提供了丰富的操作接口，利用<strong>DAG</strong>进行统一的任务规划</em>。使得Spark能够更加灵活地处理类似MapReduce的批处理作业。 <br>
<code>在Spark Core之上，有Shark/Spark SQL、Spark Streaming、GraphX、MLlib</code>。</p>

<p><code>Spark生态系统的目标：</code>
将<em>批处理、交互式处理、流式处理</em>融合到同一个<strong>软件栈</strong>中。</p>

<p><code>对于最终的用户或者开发者而言，Spark生态系统有如下特性：</code> <br>
1.<strong>Spark生态系统兼容Hadoop生态系统</strong>  —— <br>
完美兼容Hadoop生态中的HDFS和YARN等其他组件，使得现有的Hadoop用户能够非常容易地迁移到Spark系统中（虽然Spark通用引擎在一定程度上是用来取代MapReduce系统的）</p>

<p>2.<strong>Spark生态系统学习成本很低</strong> <br>
<code>开发者对Spark Core的原理有比较深入的理解，对架构在Spark Core之上的其他组件的运用将会非常容易。</code> <br>
3.<strong>Spark性能表现优异</strong> <br>
 由于Spark利用<em>DAG</em>进行调度执行规划，所以在多任务计算以及迭代计算中能够大量减少磁盘I/O的时间。 <br>
对于每一项任务<em>启动一个线程</em>，而不是启动一个进程，大大缩短了任务启动时间。 <br>
4.<strong>Spark有强大的社区支持</strong> <br>
Spark创业团队成立Databricks公司，全力支持Spark生态的发展。 <br>
5.<strong>Spark支持多种语言编程接口</strong> <br>
<em>Spark生态本身是使用Scala语言编写的</em>，
考虑到流行性，Spark从一开始就支持Java和Python接口，方便开发者自由选择。</p>
<!-- content end -->
</div>
<br>
<br>
    <div id="disqus_thread"></div>
	<div class="footer">
		<p>© Copyright 2014 by isnowfy, Designed by isnowfy</p>
	</div>
</div>
<script src="main.js"></script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ["\\(", "\\)"]], processEscapes: true}});
</script>
<script id="content" type="text/mustache">
    <h1>{{title}}</h1>
    <div class="tag">
    {{date}}
    {{#tags}}
    <a href="/#/tag/{{name}}">#{{name}}</a>
    {{/tags}}
    </div>
</script>
<script id="pagesTemplate" type="text/mustache">
    {{#pages}}
    <li>
        <a href="{{path}}">{{title}}</a>
    </li>
    {{/pages}}
</script>
<script>
$(document).ready(function() {
    $.ajax({
        url: "main.json",
        type: "GET",
        dataType: "json",
        success: function(data) {
            $("#title").html(data.name);
            var pagesTemplate = Hogan.compile($("#pagesTemplate").html());
            var pagesHtml = pagesTemplate.render({"pages": data.pages});
            $("#pages").append(pagesHtml);
            //path
            var path = "spark_system_overview.html";
            //path end
            var now = 0;
            for (var i = 0; i < data.posts.length; ++i)
                if (path == data.posts[i].path)
                    now = i;
            var post = data.posts[now];
            var tmp = post.tags.split(" ");
            var tags = [];
            for (var i = 0; i < tmp.length; ++i)
                if (tmp[i].length > 0)
                    tags.push({"name": tmp[i]});
            var contentTemplate = Hogan.compile($("#content").html());
            var contentHtml = contentTemplate.render({"title": post.title, "tags": tags, "date": post.date});
            $("#main").prepend(contentHtml);
            if (data.disqus_shortname.length > 0) {
                var disqus_shortname = data.disqus_shortname;
                (function() {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            }
        }
    });
});
</script>
</body>
</html>
